# Working with data

NEEDS A LOT OF EDITS

How do we manipulate the data to tell a story


1. How to get data from your collaborators  into a format for R...
2. how to organize data 
3.how to explore data


As we talked about in the previous chapter, most data live in spreadsheets.


## Tidy data
[maybe talk about this in the spreadsheet chpt?]

Data transformation is the key to R. we are going to take data in from a worksheet/csv/whatever and transform it.

There are a number of ways to do this. One  method that gives us many options is using a package called *dplyr.* This is part of a larger group of packages known as the *Tidyverse.*


## examples

- data i used from NSF 
- use data from the primate database
- a few from Tidytuesday so they are introduced to that
- another anthro dataset


## getting data into R

While it has gotten easier over the years to do this, one of the major struggles first-time R users (and seasoned professionals) have is getting data from a file into R. In this section we give a few different methods of doing this. 

examples:
read.csv and read_csv
using the 'import dataset' button
read_xl
datapasta
etc..




### reading in a CSV file

if you are lucky the data sent to you is in a CSV file  (see chpt 5 \@ref(Working with Spreadsheets)) for tips on what to do if this is not the case).

There are XXX ways to do this

#### read.csv vs read_csv vs fread (from data.table)



These are very similar functions. The read.csv is part of base R whil read_csv is from the Tidyverse. Most of the differences between the two functions aren't really useful for us (see XXXX for details) but there are two things to mention. One is that unlike read.csv, read_csv doesn't automatically imports strings as factors. This might be useful since the assumption that strings should be factors has a bit of history attached to it ![](https://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/). Moreover, read_csv seems to do a better job of 'guessing' the type of data in each column. It parses  the cols and puts them in the data type that it guesses they should be in


read_csv also tells you what it parsed each col as.

fread has the nice output that it tells you had big the file is

read_csv will import the data as a tibble vs as a dataframe so keep that in mind. It is also faster than read.csv, while fread seems to be the fastest overall 

As with anything, people disagree about this. honestly you caa get bogged down in this or just pick one and learn that one. and if you need a different method know it exists.

also, keep in mind that there are other types of data you can read in with these. 

examples:


```{r}
library(tidyverse)
library(data.table)

body_mass_base <- read.csv("https://zenodo.org/record/2600338/files/BodyMass.csv")

body_mass_tidy <- read_csv("https://zenodo.org/record/2600338/files/BodyMass.csv")

body_mass_datatable <- fread("https://zenodo.org/record/2600338/files/BodyMass.csv")
```


> look at each of the objects imported above. compare them with str function. What differences do you see? 

If you are using Rstudio there is another way to do this. if you look at the enviotnment pane you will see an 'import dataset' button (next to the little broom). clicking that gives you a point-and-click interface that will generate the function calls to read in various datasets

> using the button play around with the various options in readr and see what you can find out. HOw can you change the way readr parses a speicfic col? 


### reading in a Excel file

How to import/ a dataset from Excel into R:
I. Open Excel data 
a.  File/ Save As/ Name/ *Before clicking save, make sure to change the file format to Comma Delimited Text and better set the directory to My Documents folder, for Windows
b. When Saved, this file will have a name Data.csv. 
II   Now Open R and run 
a.     MyRData <- read.csv(“Data.csv”, header = TRUE) 
                                               i.     The argument header= TRUE tells R that the first row of the data labels of every column 
1.   If set to FALSE then the first row of the data are not labels but are considered as data points
b.    If data is saved in Text (.txt) format, use the read.table function
                                               i.     Run 
  MyRData2 <- read.table(“Data1.text”, header = TRUE) 

read_xl





### Datapasta



### cleaning the data once it is in R

sometimes the col heads are messy. the wonderful janitor package comes in useful here


```{r}
home_range <- read_csv("https://zenodo.org/record/2600338/files/HomeRange.csv")
home_range_clean <- janitor::clean_names(home_range)
```

> How does home_range differ from home_range_clean? look at the online help for the Janitor package and figure out what other functions it has? how would you find duplicate rows of data? 




## You got the data into R, now what?

Once you get data into R the question becomes what to do with it. 
EDA 
when doing EDA we need to be careful. as you 'explore' data you are also affecting your view of it. for example as we look at the dataset we may play around and start to see patterns. these patterns might be there because we choose to look for patterns and not becuse they are real..good practice is to take a 'training set' of your data and explore that.
Or use a dataset that you aren't studying to learn

## lets look at the primate dataset

This comes from https://www.nature.com/articles/s41597-019-0059-9



```{r}
body_mass <- read_csv("https://zenodo.org/record/3368372/files/BodyMass.csv")

diel_activity <- read_csv("https://zenodo.org/record/3368372/files/DielActivity.csv")

habitat <- read_csv("https://zenodo.org/record/3368372/files/Habitat.csv")


home_range <- read_csv("https://zenodo.org/record/3368372/files/HomeRange.csv")


IUCN_Poptrend_Realm <-read_csv("https://zenodo.org/record/3368372/files/IUCN_Poptrend_Realm.csv")

Locomotion <- read_csv("https://zenodo.org/record/3368372/files/Locomotion.csv")


TrophicGuild <- read_csv("https://zenodo.org/record/3368372/files/TrophicGuild.csv")
```


#dataAnim



### viewing the data

```{r}
home_range <- read_csv("https://zenodo.org/record/2600338/files/HomeRange.csv")

```

we can explore the data that is in R with different functions.

just enter the name of the object spits out some info

```{r}
home_range
print(home_range)
```

notes a couple of things about the output in the console.

1. it might not all fit on the screen
2. if you scroll to the top you see that it is a 'tibble' that is 748 x 15. This means there are 748 rows and 15 columns

FIND ANOTHER DATASET
> how many observatiosn are ther
> How many variables? 
 
If you want to see just the first few rows use head

```{r}
head(home_range)
tail(home_range)
```

You can also use the built-in dataviwer with the View function. this makes a spreadsheet that you can quickly explore

```{r}
View(home_range)
```

finally, if the data is a tibble you can use glimpse

```{r}
glimpse(home_range)
```

>what differences exist betwen print and glimpse


### exploring the data

Much of this usse the dplyr package which is part of the tidyverse. We also show how to use the data.tables pacakge as well.

As its authors point out, a good way to think of dplyr is in terms of verbs. the verbs do things to the object

#### count

this function provides a count by varibale 

```{r}
count(home_range, Family)

```

> look at the help for count and figure out how to make it order the output from large to small


add_count adds a new col at the end of the dataframe with these data

```{r}
 add_count(home_range, Family, name = "family_count") 
```

Count is a great way to start exploring your dataset. 



One nice way to make complex code easier to read is to chain arguments togehter w/ the "%>%" symobl. This comes from the AAAAAA pacakage and also is loaded when you load the tidyverse. the %>%  can be read as "then"

so the same code to get the counts of Famlies can be done like this

```{r}
home_range %>% count(Family, sort = T)
```

This is sometimes easier when you have a long code and want to make it readable


#### Filter


this function searches for rows that match the arguement. For example, lets say you want all the speices in the genus Allenopithecus

**note the == rather than =**

```{r}
filter(home_range, Genus == "Macaca")
#or

home_range %>% filter(Genus == "Macaca")
```


You can do more complex filters too:

lets say you want two genra

```{r}
filter(home_range, Genus == "Macaca" | Genus == "Allochrocebus")
```

or you want to match two varibales

```{r}
filter(home_range, Genus == "Macaca" & N_groups == 2)
```






> how would you find HomeRange_ha greater than 75 and then save that to a new dataset. look at the dplyr help to figure this out

```{r}
over75 <- filter(home_range, HomeRange_ha > 75)
```



#### Select


this verb searches the dataframe and only returns cols that you ask for. For example. lets say i just want the speceis and home range

```{r}
home_range %>% select(Species, HomeRange_ha)
```

This is useful when you want to look at only some things

> select has a lot of arguments. HOw would you select all the cols that habe the startes with the prefix "Alt"



YOu can also chain verbs together

```{r}
home_range %>% filter(Genus == "Macaca") %>% select(Species)
```


#### arrange

this sorts the data

```{r}
home_range %>% arrange(HomeRange_ha)
```

if you put a minus sign in from of the variable it will organiz in descnein order


```{r}
home_range %>% arrange(-HomeRange_ha)
#or
home_range %>% arrange(desc(HomeRange_ha))
```

#### mutate

This is a powerhouse and one that you will probably use a lot. it is simialr to some of the stuff you might do in Excel

maybe we want our data in lbs and not grams!

```{r}
body_mass_updated <- body_mass %>% mutate(BodyMass_lbs = BodyMass_kg * 2.20462 )
```

#### summarise

```{r}
home_range %>% summarise(mean(HomeRange_ha, na.rm =T))
home_range %>% group_by(Family) %>% summarise(mean(HomeRange_ha, na.rm =T))
```


#### MORE




## adding datasets together

take a look at the datasets body_mass and home range. Maybe you want to know if the body_mass predicts home range. But the data are in two different datasets?


to do this we use what is known as a join. There are a few ways to do this but probably the easiest is the version from the Tidyverse

(see https://dplyr.tidyverse.org/reference/join.html)

in a join, you tell R which two datasets you want to join together and then *how* you want to join them
- A left join: takes all the rows in first dataset ands adds to them the cols in the second dataset. if the first dataset has a row that doesn't match the second, the new cols for that row have NAs

- a right join: opposite of the left join

- inner join: gives all the rows of the first dataset that match the second

- full join: if there are no matches in left or right dataset it keeps those rows and adds NAs to the cols

- anti_join: only gives  rows from the first that don't match the second

-nest join: ????



example:

when doing a join you often want to specify which col in the left dataset is to be matched to the one in the right. Join will attempt to guess this if you don't tell it. sometimes the guess is right but i think it best to tell it what you want. This is easy when the col names match

lets join body_mass and home range



```{r}

a <- body_mass %>% left_join(home_range, by = ("CommonName"))


b <-body_mass %>% left_join(home_range)


```

notice above that a we told it to just use the common name col. but when we didn't say whihc to use it used all the cols in common. "Family", "Genus", "CommonName", "Species", "Species (ITIS)". also note that a is larger than B. we cna figure out what didn't match the second time using an anti-join

```{r}

a %>% anti_join(b) # found in a but not in b

a %>% filter()
b %>% anti_join(a) # found in b but not in a
```




> why are the matches different? how might you figure this out? what is causing the problem here

ANSWER: note a %>% filter(Genus.x != Genus.y) %>% select(Genus.x, Genus.y, CommonName)


In this case maybe we will stick with the ones that are more conservativly matched and thus use the b dataset. but the point is that join helps a lot

```{r}

b %>% ggplot(aes(x=BodyMass_kg, y =HomeRange_ha)) + geom_point() + geom_smooth(method="lm")
b %>% ggplot(aes(x=BodyMass_kg, y =HomeRange_ha, color = Family)) + geom_point() + scale_x_log10() + scale_y_log10()

b %>% ggplot(aes(x=BodyMass_kg, y =HomeRange_ha)) + geom_point() + geom_smooth(method="lm") + scale_x_log10() + scale_y_log10()

fit <- lm(HomeRange_ha ~BodyMass_kg, data= b )
summary(fit)
library(broom)
tidy(fit)
augment(fit)
glance(fit)
```


ADD WHAT TO DO WHEN COL NAMES DONT MATCH

Sometimes you want to join two datasets where the key columns don't have the same name. This happens often when trying to make maps (SEE CHPT XXXX). To do this we just need to tell R which cols are equal

GIVE BETTER EXAMPLE HERE

```{r}
#a %>% left_join(b, by = c("a_name" = "b_name ))
```


{find that package that does the visualization of joining }


A cool package to help you understand joijns is the dataAnim one

```{r}
#dataAnim
devtools::install_github("chrk623/dataAnim")

library(dataAnim)
data(datoy1)
join_anim(join_type = "left", speed = 1, x = datoy1$x, y = datoy1$y, by = "Name", show_msg = T)
join_anim(join_type = "inner", speed = 1, x = datoy1$x, y = datoy1$y, by = "Name", show_msg = T)
join_anim(join_type = "full", speed = 1, x = datoy1$x, y = datoy1$y, by = "Name", show_msg = T)
data(datoy_wide)
gather_anim(key = "Subject", value = "Score", col = c("English", "Maths"), data = datoy_wide)


join_anim(join_type = "left", speed = 1, x = temp$x, y = temp$y, by = "Name", show_msg = T)


```



### Viewing your data

SEE MORE IN VISULAZTION CHPT
see examples in primate.rmd




## another example

```{r}
squirrel_raw <- read_csv("datasets/2018_Central_Park_Squirrel_Census_-_Squirrel_Data (1).csv")
squirrel <- squirrel_raw %>% janitor::clean_names()
squirrel %>% count(date, sort=T)

library(lubridate)
squirrel %>% mutate(parsed_date = mdy(date))

squirrel <- squirrel %>% mutate(date = mdy(date))
squirrel  <- squirrel %>% mutate(month = month(date, label = T))
squirrel <- squirrel %>% mutate(day = wday(date, label=T))


squirrel %>% select(other_interactions) %>% filter(!is.na(other_interactions)) %>%  View()

squirrel %>% count(other_interactions, sort=T)
squirrel %>% count(other_activities, sort=T)

squirrel %>% group_by(day) %>%  add_count() %>%  ggplot(aes(day,n )) + geom_line(group=1)


```



```{r}
squirrel %>% count(primary_fur_color)
squirrel %>% count(combination_of_primary_and_highlight_color, sort=T)

squirrel %>% ggplot(aes(x,y)) + geom_point()  + labs(title = "squirrel data for 3,023 sightings in Central Park", caption = "from: https://data.cityofnewyork.us/Environment/2018-Central-Park-Squirrel-Census-Squirrel-Data/vfnx-vebw")

squirrel %>% ggplot(aes(x,y, color = primary_fur_color)) + geom_point()

squirrel %>% ggplot(aes(x,y, color = primary_fur_color)) 

library(leaflet)

squirrel %>% leaflet() %>%  addTiles() %>% addMarkers(lat = ~x, lng = ~y)
```

